
You are a bug repair agent to resolve issues and submit pull requests.
Now You need to reolve the following issue in the **sphinx** project:
## ISSUE
<ISSUE>
linkcheck could also check local (internal) links
Subject: linkcheck currently doesn't check local (internal) links, but this would be useful.

<!--
  Important: This is a list of issues for Sphinx, not a forum.
  If you'd like to post a question, please move to sphinx-users group.
  https://groups.google.com/forum/#!forum/sphinx-users

  Thanks,
-->

### Problem
See above.

#### Procedure to reproduce the problem
Create a template project with sphinx-quickstart, put the following in index.rst
```
broken external-link_
broken local-link_

.. _external-link: https://lkfqhlkghflkhs
.. _local-link: doesntexist
```

Run `make linkcheck`

#### Error logs / results
```
Running Sphinx v1.7.6
making output directory...
loading pickled environment... done
building [mo]: targets for 0 po files that are out of date
building [linkcheck]: targets for 1 source files that are out of date
updating environment: 0 added, 0 changed, 0 removed
looking for now-outdated files... none found
preparing documents... done
writing output... [100%] index                                                                   
(line   14) -local-   doesntexist
(line   14) broken    https://lkfqhlkghflkhs - HTTPSConnectionPool(host='lkfqhlkghflkhs', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7faed7ddfc88>: Failed to establish a new connection: [Errno -2] Name or service not known',))

build finished with problems.
make: *** [Makefile:20: linkcheck] Error 1
```

#### Expected results
Also a check for the local link.

### Reproducible project / your project
N/A

### Environment info
- OS: Arch Linux
- Python version: 3.6
- Sphinx version: 1.7.6


</ISSUE>


A debugging agent has tried to trace the abnormal program and locate the root cause of the bug. This is its debugging history:

==================================================
Since the issue describes a problem where local (internal) links are not being checked by the `linkcheck` builder in Sphinx, and given that the output also suggests a failure in detecting broken local links, we should start by examining the code in Sphinx responsible for handling and checking links in the documentation.

Given the context, it is likely that the relevant code will reside in the modules related to the `linkcheck` builder, as this builder is responsible for validating links.

Therefore, the next logical step is to dive into the `linkcheck` builder and explore how it processes links. We need to trace the methods involved in link validation to identify where local links might not be accounted for. 

Let's observe the `sphinx.builders.linkcheck` module, focusing particularly on the method responsible for collecting and checking links.

Observed method: `sphinx/builders/linkcheck.py:LinkCheckBuilder.get_outdated_docs`
==================================================
Based on the runtime information and the code snippet provided for the `CheckExternalLinksBuilder.get_outdated_docs` method, we can see that the function simply returns `self.env.found_docs`. This method isn't directly related to checking links but rather indicates which documents have changed and thus need to be processed again. This information alone does not help us directly in resolving the issue at hand, which concerns checking local (internal) links through the `linkcheck` builder.

The issue here seems to arise from the `linkcheck` builder's lack of capability to check local links, as revealed in the original problem description and testing output: the test appears to be passing in this context, but that means it correctly identifies remote links and local links at some level.

A deeper inspection is necessary to understand the part of the code responsible for scanning and validating internal links, specifically local (relative) links, as this part does not currently report broken local links in the issue described.

To address this, we should trace how links are processed within the builder beyond just marking outdated documents; hence, I will follow the path concerning link processing logic.

Observed scope: `sphinx/builders/linkcheck.py:100-150`
==================================================
The issue is about the Sphinx `linkcheck` builder not reporting broken local (internal) links. The test case highlights that the linkcheck builder currently successfully identifies broken external links but fails to handle or report on local links, as evidenced by the lack of error messages related to the "doesntexist" local link.

From the observed code snippet inside `CheckExternalLinksBuilder.get_outdated_docs`, it is evident that this method deals with initiating worker threads to handle link checking. The specific logic for handling the URI (link) checking is encapsulated in the `check_thread` method. The `check_uri` function nested inside `check_thread` is particularly handling URI validation, with specific attention to anchors and non-ASCII handling.

Since we've observed how the `check_thread` is initialized but not fully traced through how it handles internal links, it seems plausible that the `check_thread` or parts of logic encapsulated within it could be the site of the bug.

To verify these assumptions and delve further into the potential oversight for local links, the next step is to trace the `check_uri` function further. This will provide insight into how URIs, including local links, are parsed and validated, potentially revealing the absence or mishandling of checks for local links.

Observed method: `sphinx/builders/linkcheck.py:CheckExternalLinksBuilder.check_thread`
==================================================
The `check_thread` method, specifically the nested `check_uri` function, identifies whether a URI (link) is broken or not by attempting HTTP/HTTPS requests if applicable. The method `check` determines if a URI is internal or not with the line:

```python
elif not uri.startswith(('http:', 'https:')):
    return 'local', '', 0
```

This snippet categorizes links as "local" and simply returns without thoroughly checking if these local links actually exist in the documentation. This implies that the `linkcheck` builder is mainly checking the schemed links (e.g., `http`, `https`) for validity and skips comprehensive checks for non-schemed (local/internal) links. This is consistent with the issue reported in the problem.

To address this, an enhancement or extension to the current behavior is needed where the linkcheck builder should verify if the local links correctly point to existing targets within the documentation.

Given the understanding of the current behavior:

- The `check` function recognizes and categorizes local links but lacks the steps to ensure they resolve to actual document targets.

Thus, the next step is to implement or identify the mechanism needed to properly resolve and verify these 'local' links.

Buggy method: `sphinx/builders/linkcheck.py:CheckExternalLinksBuilder.check_thread`
==================================================

You have called API to retrieve some code and this is your API call and reply history:
==================================================
Your Output:
To proceed with generating a patch for the identified issue, I first need to examine the source code for the `CheckExternalLinksBuilder.check_thread` method, specifically focusing on how it handles local links. This will allow me to understand what changes are necessary to implement checks for local (internal) links effectively.

Therefore, I will retrieve the source code for the `check_thread` method within the `CheckExternalLinksBuilder` class located in the `sphinx/builders/linkcheck.py` file.

```python
search_method_in_file("sphinx/builders/linkcheck.py", "CheckExternalLinksBuilder.check_thread")
```
==================================================
Your API invoke result:

### API INVOKE: search_method_in_file("sphinx/builders/linkcheck.py", "CheckExternalLinksBuilder.check_thread")
RESULT:
#### sphinx/builders/linkcheck.py:CheckExternalLinksBuilder.check_thread
```python
    def check_thread(self) -> None:
        kwargs = {
            'allow_redirects': True,
        }  # type: Dict
        if self.app.config.linkcheck_timeout:
            kwargs['timeout'] = self.app.config.linkcheck_timeout

        def get_request_headers() -> Dict:
            url = urlparse(uri)
            candidates = ["%s://%s" % (url.scheme, url.netloc),
                          "%s://%s/" % (url.scheme, url.netloc),
                          uri,
                          "*"]

            for u in candidates:
                if u in self.config.linkcheck_request_headers:
                    headers = dict(DEFAULT_REQUEST_HEADERS)
                    headers.update(self.config.linkcheck_request_headers[u])
                    return headers

            return {}

        def check_uri() -> Tuple[str, str, int]:
            # split off anchor
            if '#' in uri:
                req_url, anchor = uri.split('#', 1)
                for rex in self.anchors_ignore:
                    if rex.match(anchor):
                        anchor = None
                        break
            else:
                req_url = uri
                anchor = None

            # handle non-ASCII URIs
            try:
                req_url.encode('ascii')
            except UnicodeError:
                req_url = encode_uri(req_url)

            # Get auth info, if any
            for pattern, auth_info in self.auth:
                if pattern.match(uri):
                    break
            else:
                auth_info = None

            # update request headers for the URL
            kwargs['headers'] = get_request_headers()

            try:
                if anchor and self.app.config.linkcheck_anchors:
                    # Read the whole document and see if #anchor exists
                    response = requests.get(req_url, stream=True, config=self.app.config,
                                            auth=auth_info, **kwargs)
                    found = check_anchor(response, unquote(anchor))

                    if not found:
                        raise Exception(__("Anchor '%s' not found") % anchor)
                else:
                    try:
                        # try a HEAD request first, which should be easier on
                        # the server and the network
                        response = requests.head(req_url, config=self.app.config,
                                                 auth=auth_info, **kwargs)
                        response.raise_for_status()
                    except HTTPError:
                        # retry with GET request if that fails, some servers
                        # don't like HEAD requests.
                        response = requests.get(req_url, stream=True, config=self.app.config,
                                                auth=auth_info, **kwargs)
                        response.raise_for_status()
            except HTTPError as err:
                if err.response.status_code == 401:
                    # We'll take "Unauthorized" as working.
                    return 'working', ' - unauthorized', 0
                elif err.response.status_code == 503:
                    # We'll take "Service Unavailable" as ignored.
                    return 'ignored', str(err), 0
                else:
                    return 'broken', str(err), 0
            except Exception as err:
                if is_ssl_error(err):
                    return 'ignored', str(err), 0
                else:
                    return 'broken', str(err), 0
            if response.url.rstrip('/') == req_url.rstrip('/'):
                return 'working', '', 0
            else:
                new_url = response.url
                if anchor:
                    new_url += '#' + anchor
                # history contains any redirects, get last
                if response.history:
                    code = response.history[-1].status_code
                    return 'redirected', new_url, code
                else:
                    return 'redirected', new_url, 0

        def check() -> Tuple[str, str, int]:
            # check for various conditions without bothering the network
            if len(uri) == 0 or uri.startswith(('#', 'mailto:', 'ftp:')):
                return 'unchecked', '', 0
            elif not uri.startswith(('http:', 'https:')):
                return 'local', '', 0
            elif uri in self.good:
                return 'working', 'old', 0
            elif uri in self.broken:
                return 'broken', self.broken[uri], 0
            elif uri in self.redirected:
                return 'redirected', self.redirected[uri][0], self.redirected[uri][1]
            for rex in self.to_ignore:
                if rex.match(uri):
                    return 'ignored', '', 0

            # need to actually check the URI
            for _ in range(self.app.config.linkcheck_retries):
                status, info, code = check_uri()
                if status != "broken":
                    break

            if status == "working":
                self.good.add(uri)
            elif status == "broken":
                self.broken[uri] = info
            elif status == "redirected":
                self.redirected[uri] = (info, code)

            return (status, info, code)

        while True:
            uri, docname, lineno = self.wqueue.get()
            if uri is None:
                break
            status, info, code = check()
            self.rqueue.put((uri, docname, lineno, status, info, code))

```


==================================================

Based on these information, you need to think about how to resolve the issue and fix the bug.
Now, please first analyze whether you need to retrieve any source code or if you're ready to generate the patch. Note that before generating a patch for a method, you must first obtain its source code.
Then you have two options. (Choose only one of them):

## IF GENERATE PATCH
If you've gathered enough code to generate the patch, stop invoking the search APIs.
At this point, instead of invoking function call, please reply with:
Ready generation: `True` 

## IF YOU NEED TO RETRIEVE SOURCE CODE
If you need to know any more source code to help you generate the patch, use the search APIs to retrieve code.
You can use the following APIs to search source code.
1. `search_method_in_file(file_path: str, method_name: str)`: Search for the method in the specified file.
2. `search_method_in_codebase(method_name: str)`: Search for the method in the whole project codebase. Only if you don't know the file path of the method, this API should be used. Otherwise, you should use the `search_method_in_file` API.
3. `search_class_in_file(file_path: str, class_name: str)`: Search for the class code in the specified file.
4. `search_class_in_codebase(class_name: str)`: Search for the class code in the whole project codebase. Only if you don't know the file path of the class, this API should be used. Otherwise, you should use the `search_class_in_file` API.
5. `search_code_in_file(file_path: str, code: str)`: Search for a code snippet in the specified file, return its surrounding code.
6. `search_code_in_codebase(code: str)`: Search for a code snippet in the whole project codebase. Only if you don't know the file path of the code, this API should be used. Otherwise, you should use the `search_code_in_file` API.


You should finally reply in the following format:
```python
search_method_in_file("FILE_PATH", "METHOD_NAME")
search_class_in_file("FILE_PATH", "CLASS_NAME")
search_code_in_file("FILE_PATH", "SOME_CODE")
search_method_in_codebase("METHOD_NAME")
...
```
Note the format should obeys the following rules:
1. Enclose all API calls in a single python code block (i.e., start with ```python, followed by the API calls, then close the block with ```).
2. You may invoke any of these APIs as many times as needed, including not at all.
3. The file path is relative to the repository.
4. All arguments must be enclosed in double quotes and the number of arguments must be correct.
5. If the method you want to search belongs to a class, it is recommended specify the class name and method name in the format of `ClassName.method_name` as METHOD_NAME. Otherwise multiple methods with the same name (but in different classes) may be returned.


Now, please first analyze whether you need to retrieve any source code or if you're ready to generate the patch. Note that before generating a patch for a method, you must first obtain its source code.
Then choose one of the two options above and follow the format to reply.

