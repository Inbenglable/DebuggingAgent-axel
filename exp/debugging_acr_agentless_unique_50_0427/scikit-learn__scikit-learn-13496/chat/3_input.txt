
You need to trace the abnormal program to resolve project issues and submit pull requests.
Now you need to reolve the following issue in the **scikit-learn** project:
## ISSUE
<ISSUE>
Expose warm_start in Isolation forest
It seems to me that `sklearn.ensemble.IsolationForest` supports incremental addition of new trees with the `warm_start` parameter of its parent class, `sklearn.ensemble.BaseBagging`.

Even though this parameter is not exposed in `__init__()` , it gets inherited from `BaseBagging` and one can use it by changing it to `True` after initialization. To make it work, you have to also increment `n_estimators` on every iteration. 

It took me a while to notice that it actually works, and I had to inspect the source code of both `IsolationForest` and `BaseBagging`. Also, it looks to me that the behavior is in-line with `sklearn.ensemble.BaseForest` that is behind e.g. `sklearn.ensemble.RandomForestClassifier`.

To make it more easier to use, I'd suggest to:
* expose `warm_start` in `IsolationForest.__init__()`, default `False`;
* document it in the same way as it is documented for `RandomForestClassifier`, i.e. say:
```py
    warm_start : bool, optional (default=False)
        When set to ``True``, reuse the solution of the previous call to fit
        and add more estimators to the ensemble, otherwise, just fit a whole
        new forest. See :term:`the Glossary <warm_start>`.
```
* add a test to make sure it works properly;
* possibly also mention in the "IsolationForest example" documentation entry;


</ISSUE>


Based on this issue, the testing agent has generated a reproducible test:
import traceback
import sys
from sklearn.ensemble import IsolationForest
from sklearn.datasets import make_classification
import numpy as np

def print_stacktrace(e: Exception):
    tb = traceback.extract_tb(e.__traceback__)
    print("Traceback (most recent call last):", file=sys.stderr)
    for frame in tb:
        line_number = frame.lineno
        code_context = frame.line.strip() if frame.line else "Unknown"
        print(f'  File "{frame.filename}"', file=sys.stderr)
        print(f"    {line_number}: {code_context}", file=sys.stderr)
    print(f"{e.__class__.__name__}: {e}", file=sys.stderr)

def main():
    # Create a synthetic dataset
    X, _ = make_classification(n_samples=100, n_features=20, random_state=42)

    # Initialize the IsolationForest without warm_start exposed
    iso_forest = IsolationForest(n_estimators=10, random_state=42)

    # Fit the model
    iso_forest.fit(X)

    # Try to use warm_start by setting it manually
    try:
        iso_forest.set_params(warm_start=True)
        iso_forest.set_params(n_estimators=20)
        iso_forest.fit(X)
    except Exception as e:
        print_stacktrace(e)
        raise AssertionError("IsolationForest does not support warm_start as expected.")

    # If no exception is raised, the issue might be fixed
    print("The issue is not present, warm_start seems to be working as expected.")
    sys.exit(0)

if __name__ == "__main__":
    main()


This is the tracing and analysis history:

==================================================
Based on the provided log, the issue arises because the `warm_start` parameter is not exposed in the `IsolationForest` class, resulting in a `ValueError` when attempting to set it via `set_params`. 

From the traceback, the `ValueError` is triggered in the `set_params` method because `warm_start` is not listed in the valid parameters for the `IsolationForest` estimator.

To locate the source of this problem, I need to investigate the constructor of `IsolationForest` to determine how parameters are defined and which are exposed.

Observed method: `sklearn/ensemble/iforest.py:IsolationForest.__init__`
==================================================


Now you choose downstream method IsolationForest.__init__ to further observe, tracing the abnormal program behavior.
This is the method code:
   167	    def __init__(self,
   168	                 n_estimators=100,
   169	                 max_samples="auto",
   170	                 contamination="legacy",
   171	                 max_features=1.,
   172	                 bootstrap=False,
   173	                 n_jobs=None,
   174	                 behaviour='old',
   175	                 random_state=None,
   176	                 verbose=0):
   177	        super().__init__(
   178	            base_estimator=ExtraTreeRegressor(
   179	                max_features=1,
   180	                splitter='random',
   181	                random_state=random_state),
   182	            # here above max_features has no links with self.max_features
   183	            bootstrap=bootstrap,
   184	            bootstrap_features=False,
   185	            n_estimators=n_estimators,
   186	            max_samples=max_samples,
   187	            max_features=max_features,
   188	            n_jobs=n_jobs,
   189	            random_state=random_state,
   190	            verbose=verbose)
   191	
   192	        self.behaviour = behaviour
   193	        self.contamination = contamination


This is the runtime information of IsolationForest.__init__:

Traceback (most recent call last):
  File "run_debugging_test.py", line 38, in <module>
    debugging_test_execution_wrapper(args.test_path, file_scope_dict, args.depth, args.loop)
  File "run_debugging_test.py", line 13, in debugging_test_execution_wrapper
    @dbgsnooper.snoop(file_scope_dict=file_scope_dict, depth=depth, loop=loop)
  File "/data/swe-fl/SRC/pysnooper_axel/dbgsnooper/dbgsnooper/tracer.py", line 249, in __init__
    assert os.path.exists(file_path)
AssertionError

ERROR conda.cli.main_run:execute(125): `conda run python run_debugging_test.py --test-path /data/swe-fl/TMP/testbed/scikit-learn__scikit-learn-13496/reproduce.py --file-scope-dict {"/data/swe-fl/SRC/DebuggingAgent/src/sklearn/ensemble/iforest.py": [167, 193]} --depth 1` failed. (See above for error)


You need to trace the abnormal program behavior step by step to identify the root cause of the bug and locate the buggy method that contains the code to be fixed.
Now, please first analyze the current observed code and the abnormal program behavior. 

Then, if you can already locate the buggy method and buggy code, reply with:  
Buggy method: `{FILE_PATH}:{METHOD_NAME}`
Otherwise, continue tracing by telling me the code line scope that you want to deeper observe, we will show you the deeper downstream run-time information of the scope you select. Please reply with:
Observed scope: `{FILE_PATH}:{START_LOC}-{END_LOC}`
Note that {FILE_PATH} refers to the path relative to the repository.

